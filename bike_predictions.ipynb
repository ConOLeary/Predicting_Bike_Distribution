{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS & DEFINITIONS\n",
    "\n",
    "import csv, sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np; np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DUD_VALUE= 0 # change from 0 to something like 123 for debugging\n",
    "EMPTY_DATA_DAY_VAL= 123456789\n",
    "TOTAL_ROWS= 999999999\n",
    "INPUT_ROWS_LIMIT= TOTAL_ROWS # 500000\n",
    "FILENAME= 'dublinbikes_2020_Q1.csv'\n",
    "MAX_STATIONS= 118\n",
    "SECS_IN_5MIN= 300\n",
    "DATAPOINT_EVERYX_MIN= 5\n",
    "DATAPOINTS_PER_DAY= 288\n",
    "DAYS_OF_WEEK= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] # yes, I consider Monday to be the '0'/start of the week\n",
    "STARTING_DATE= 0 # aka Monday. Because the 27th of Jan 2020 is a Monday\n",
    "MISSING_STATIONS= [117, 116, 70, 60, 46, 35, 20, 14, 1, 0]\n",
    "NUM_STATIONS= MAX_STATIONS - len(MISSING_STATIONS)\n",
    "SUBSTANDARD_DAYS= [] # [50, 49]\n",
    "TOTAL_DAYS= 66 # from 27 / 1 / 2020 to (and including) 1 / 4 / 2020\n",
    "HOURS= 24\n",
    "EPOCH= datetime.datetime(2020, 1, 27, 0, 0)\n",
    "TOTAL_TIME_DATAPOINTS= int((datetime.datetime(2020,4,2,0,0) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "K= 5\n",
    "STEP_SIZE= 0.02185 # just the magic number that leads to 288 values being generated\n",
    "R= 0.5\n",
    "MAX_HINDSIGHT= 60 # minutes\n",
    "DAYS_PER_WEEKDAY= 5\n",
    "HOMEMADE_REGULISER= 0.8\n",
    "OPTIMAL_NEIGHBOURS= 30\n",
    "MAX_ERROR_DIFF= 20\n",
    "\n",
    "class DataDay: # ideally this would be nested in the Station class\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.substandard_day= False\n",
    "        if index in SUBSTANDARD_DAYS:\n",
    "            self.substandard_day= True\n",
    "        self.times_populated= 0\n",
    "        self.day_of_week= ((STARTING_DATE + index) % len(DAYS_OF_WEEK))\n",
    "        \n",
    "        self.daily_epoch_time= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.epoch_time= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.bikes= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.percent_bikes= np.full(DATAPOINTS_PER_DAY, float(EMPTY_DATA_DAY_VAL), dtype=np.float)\n",
    "\n",
    "    def populate(self, daily_epoch_time, epoch_time, bikes, percent_bikes):\n",
    "        if self.substandard_day == False:\n",
    "            self.daily_epoch_time[daily_epoch_time]= daily_epoch_time\n",
    "            self.epoch_time[daily_epoch_time]= epoch_time\n",
    "            self.bikes[daily_epoch_time]= bikes\n",
    "            self.percent_bikes[daily_epoch_time]= percent_bikes\n",
    "            self.times_populated+= 1\n",
    "\n",
    "class Station:\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.name= DUD_VALUE\n",
    "        self.bike_capacity= DUD_VALUE\n",
    "        self.address= DUD_VALUE\n",
    "        self.latitude= DUD_VALUE\n",
    "        self.longitude= DUD_VALUE\n",
    "        self.data_days= [DataDay(i) for i in range(0, TOTAL_DAYS)]\n",
    "    \n",
    "    def populate_consts(self, name, bike_capacity, address, latitude, longitude):\n",
    "        self.name= name\n",
    "        self.bike_capacity= bike_capacity\n",
    "        self.address= address\n",
    "        self.latitude= latitude\n",
    "        self.longitude= longitude\n",
    "\n",
    "def get_station_id(name):\n",
    "    try:\n",
    "        index= [x.name for x in stations].index(name)\n",
    "    except ValueError:\n",
    "        index= -1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA STRUCTURING\n",
    "\n",
    "total_capacity= 0 # not in use currently\n",
    "index= []; daily_epoch_time= []; epoch_time= []; percent_bikes= [];\n",
    "stations= [Station(i) for i in range(0, MAX_STATIONS)]\n",
    "indices_to_populate= list(range(0, MAX_STATIONS))\n",
    "for index in MISSING_STATIONS:\n",
    "    indices_to_populate.remove(index)\n",
    "\n",
    "with open(FILENAME, newline='') as f:\n",
    "    reader = csv.reader(f); next(reader) # skip data header\n",
    "    current_index= 0\n",
    "    try:\n",
    "        while len(indices_to_populate) != 0:\n",
    "            row= next(reader)\n",
    "            if int(row[0]) == current_index: # this clause is just for performance\n",
    "                continue\n",
    "            current_index= int(row[0])\n",
    "            if current_index in indices_to_populate:\n",
    "                stations[current_index].populate_consts(row[3], row[4], row[8], row[9], row[10])\n",
    "                indices_to_populate.remove(current_index)\n",
    "                total_capacity+= int(row[4])\n",
    "        \n",
    "        f.seek(0)\n",
    "        reader= csv.reader(f); row= next(reader) # skip data header\n",
    "        for row_i, row in enumerate(reader):\n",
    "            if row_i >= INPUT_ROWS_LIMIT:\n",
    "                break\n",
    "            if int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds()) < 0:\n",
    "                continue\n",
    "            try:\n",
    "                epoch_time= int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "                stations[int(row[0])].data_days[int(epoch_time / DATAPOINTS_PER_DAY)].populate( \\\n",
    "                    int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), 0, 0)).total_seconds() / (SECS_IN_5MIN)), \\\n",
    "                    epoch_time, \\\n",
    "                    int(row[6]), \\\n",
    "                    float(\"{:.3f}\".format(float(row[6]) / float(row[4]))))\n",
    "            except IndexError as e:\n",
    "                print(\"Error:\", e, int(row[0]))\n",
    "                #print(\"\\nTRIED: \", epoch_time, ' / ', DATAPOINTS_PER_DAY, ' = ', int(epoch_time / DATAPOINTS_PER_DAY))\n",
    "                #print(row[1])\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))\n",
    "            \n",
    "for station_i, station in enumerate(stations):\n",
    "    last_bikes= 0\n",
    "    last_percent_bikes= 0\n",
    "    for day_i, data_day in enumerate(station.data_days):\n",
    "        for val_i, val in enumerate(data_day.bikes):\n",
    "            if val == EMPTY_DATA_DAY_VAL:\n",
    "                stations[station_i].data_days[day_i].populate(val_i, day_i * DATAPOINTS_PER_DAY + val_i, last_bikes, last_percent_bikes)\n",
    "            else:\n",
    "                last_bikes= data_day.bikes[val_i]\n",
    "                last_percent_bikes= data_day.percent_bikes[val_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FEATURE DATA PREPERATION\n",
    "\n",
    "fullness_in10= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_in30= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_in60= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "\n",
    "fullness_percent= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.float)\n",
    "bikes_changes_pastx= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), DUD_VALUE, dtype=np.int)\n",
    "days_of_week= np.full((TOTAL_TIME_DATAPOINTS, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.int)\n",
    "hour_of_day= np.full((TOTAL_TIME_DATAPOINTS, HOURS), DUD_VALUE, dtype=np.float)\n",
    "average_weekday_fullness= np.full((DATAPOINTS_PER_DAY, NUM_STATIONS, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.float)\n",
    "weekdays_vol= np.full((NUM_STATIONS, len(DAYS_OF_WEEK)), 0, dtype=np.float)\n",
    "avrg_weekday_full= np.full((NUM_STATIONS, len(DAYS_OF_WEEK)), 0, dtype=np.float)\n",
    "meanmean= np.full(NUM_STATIONS, 0, dtype=np.float)\n",
    "\n",
    "scld_fullness_percent= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.float)\n",
    "scld_bikes_changes_pastx= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), 0, dtype=np.float)\n",
    "scld_days_of_week= np.full((TOTAL_TIME_DATAPOINTS, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.int)\n",
    "scld_hour_of_week= np.full((TOTAL_TIME_DATAPOINTS, HOURS), DUD_VALUE, dtype=np.float)\n",
    "\n",
    "station_index_decrement= 0 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for epoch_day_i in range(TOTAL_DAYS):\n",
    "    #print(\"########### epoch_day_i: \", epoch_day_i)\n",
    "    x_offset= epoch_day_i * DATAPOINTS_PER_DAY\n",
    "    y_offset= 0\n",
    "    \n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, HOURS), dtype=np.float)\n",
    "    daily_epoch_time= list(range(DATAPOINTS_PER_DAY))\n",
    "    for time_i in daily_epoch_time:\n",
    "        hour= float(\"{:.3f}\".format(time_i / 12)) # divide by 12 because there are 12 datapoints in an hour\n",
    "        block[time_i][(int(hour) + 1) % HOURS]= hour % 1\n",
    "        block[time_i][int(hour)]= 1 - (hour % 1)\n",
    "    hour_of_day[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    day_of_week= stations[2].data_days[epoch_day_i].day_of_week\n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, len(DAYS_OF_WEEK)), dtype=np.int)\n",
    "    for block_i, sub_arr in enumerate(block):\n",
    "        block[block_i][day_of_week]= 1\n",
    "    days_of_week[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    for station in stations:\n",
    "        #print(\"###### station.index: \", station.index)\n",
    "        if station.index == 0:\n",
    "            station_index_decrement= 0\n",
    "        if station.index in MISSING_STATIONS:\n",
    "            station_index_decrement+= 1\n",
    "            continue\n",
    "        y_offset= station.index - station_index_decrement\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].percent_bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness_percent[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1, 1))\n",
    "        if weekdays_vol[y_offset, day_of_week] < DAYS_PER_WEEKDAY:\n",
    "            average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset + block.shape[1], day_of_week:day_of_week+1]+= block\n",
    "            weekdays_vol[y_offset:y_offset+1, day_of_week:day_of_week+1]+= 1\n",
    "        \n",
    "        bikes= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(bikes[2:], (bikes.shape[0] - 2, 1))\n",
    "        fullness_in10[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[6:], (bikes.shape[0] - 6, 1))\n",
    "        fullness_in30[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[12:], (bikes.shape[0] - 12, 1))\n",
    "        fullness_in60[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= np.reshape(station.data_days[epoch_day_i].bikes, (DATAPOINTS_PER_DAY, 1))\n",
    "        if epoch_day_i - 1 == -1:\n",
    "            prev_block= np.zeros((DATAPOINTS_PER_DAY, 1), dtype=np.int)\n",
    "        else:\n",
    "            prev_block= np.reshape(station.data_days[epoch_day_i - 1].bikes, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_xminchange= np.zeros((DATAPOINTS_PER_DAY, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), dtype=np.int)\n",
    "        fullness_xago= np.zeros((DATAPOINTS_PER_DAY, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), dtype=np.int)\n",
    "        for col_i in range(fullness_xago.shape[1]):\n",
    "            i= col_i + 1\n",
    "            fullness_xago[i:DATAPOINTS_PER_DAY, col_i:col_i + 1]= block[0:DATAPOINTS_PER_DAY - i, 0:1]\n",
    "            fullness_xago[0:i, col_i:col_i + 1]= prev_block[DATAPOINTS_PER_DAY - i:DATAPOINTS_PER_DAY, 0:1]\n",
    "        for col_i in range(fullness_xago.shape[1]):\n",
    "            block_xminchange[0:DATAPOINTS_PER_DAY, col_i:col_i + 1]= np.subtract(block, fullness_xago[0:DATAPOINTS_PER_DAY, col_i:col_i + 1])\n",
    "        \n",
    "        bikes_changes_pastx[x_offset:x_offset + block_xminchange.shape[0], y_offset:y_offset + 1, 0:block_xminchange.shape[1]]= np.reshape(block_xminchange, (DATAPOINTS_PER_DAY, 1, block_xminchange.shape[1]))\n",
    "\n",
    "station_index_decrement= 0 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for station in stations:\n",
    "    if station.index == 0: # [117, 116, 70, 60, 46, 35, 20, 14, 1, 0]\n",
    "        station_index_decrement= 0\n",
    "    if station.index in MISSING_STATIONS:\n",
    "        station_index_decrement+= 1\n",
    "        continue\n",
    "    y_offset= station.index - station_index_decrement\n",
    "    for day_of_week_i in range(len(DAYS_OF_WEEK)):\n",
    "        average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]/= weekdays_vol[y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]\n",
    "        avrg_weekday_full[y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]= np.mean(average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset+1, day_of_week_i:day_of_week_i+1])\n",
    "    meanmean[y_offset:y_offset+1]= np.mean(avrg_weekday_full[y_offset:y_offset+1])\n",
    "\n",
    "# scld_fullness_percent= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.float)\n",
    "# scld_bikes_changes_pastx= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), 0, dtype=np.float)\n",
    "# scld_hour_of_week= np.full((TOTAL_TIME_DATAPOINTS, HOURS), DUD_VALUE, dtype=np.float)\n",
    "\n",
    "###########################################\n",
    "for station_i in range(bikes_changes_pastx.shape[1]):\n",
    "    #print(\"################### STATION\")\n",
    "    station_fullness= np.reshape(fullness_percent[0:TOTAL_TIME_DATAPOINTS, station_i:station_i+1], TOTAL_TIME_DATAPOINTS)\n",
    "    one_column= station_fullness.reshape(-1, 1)\n",
    "    scaler= MinMaxScaler((0, 1)).fit(one_column)\n",
    "    one_column= scaler.transform(one_column)\n",
    "    station_fullness= np.reshape(one_column, (station_fullness.shape[0], 1))\n",
    "    scld_fullness_percent[0:TOTAL_TIME_DATAPOINTS, station_i:station_i+1]= station_fullness\n",
    "    \n",
    "    station_pastx= np.reshape(bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, station_i:station_i+1, 0:bikes_changes_pastx.shape[2]], (TOTAL_TIME_DATAPOINTS, bikes_changes_pastx.shape[2]))\n",
    "    one_column= station_pastx.reshape(-1, 1)\n",
    "    scaler= MinMaxScaler((-1, 1)).fit(one_column)\n",
    "    one_column= scaler.transform(one_column)\n",
    "    station_pastx= np.reshape(one_column, (station_pastx.shape[0], 1, station_pastx.shape[1]))\n",
    "    scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, station_i:station_i+1, 0:bikes_changes_pastx.shape[2]]= station_pastx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH DEFINITIONS\n",
    "\n",
    "errors= np.zeros((3, MAX_ERROR_DIFF), dtype=np.int)\n",
    "\n",
    "def get_error(y_pred, y_test):\n",
    "    error= np.zeros(MAX_ERROR_DIFF, dtype=np.int)\n",
    "    for y_i, y in enumerate(y_pred):\n",
    "        for e_i in range(len(y_pred[y_i])):\n",
    "            val= y_pred[y_i][e_i]\n",
    "            val2= y_test[y_i][e_i]\n",
    "            diff= min(abs(round(val) - round(val2)), len(y_pred))\n",
    "            if diff != 0:\n",
    "                error[diff - 1]+= 1\n",
    "    if not np.any(errors[0]):\n",
    "        errors[0]= error\n",
    "    elif not np.any(errors[1]):\n",
    "        errors[1]= error\n",
    "    elif not np.any(errors[2]):\n",
    "        errors[2]= error\n",
    "    else:\n",
    "        print(\"errors array all full!\")\n",
    "\n",
    "def run_approach1(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    \n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, hour_of_day.shape[1] + days_of_week.shape[1] + 3 \\\n",
    "                + 0 * NUM_STATIONS \\\n",
    "               ), 0, dtype=np.float)\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 0:7]= day_of_week\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 7:31]= hour_of_day\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 31:32]= scld_fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index + 1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 32:33]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index + 1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 33:34]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index + 1, 1:2]), (TOTAL_TIME_DATAPOINTS, 1)) # past10\n",
    "    \n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    returns= []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        regr= MLPRegressor(random_state= 1, max_iter= 1000, alpha=0.001).fit(X_train, y_train)\n",
    "        y_pred= regr.predict(X_test)\n",
    "        score_sum+= regr.score(X_test, y_test)\n",
    "        returns.append(regr.score(X_test, y_test))\n",
    "        #print(\"R**2 score of data split\", i, \": \", regr.score(X_test, y_test))\n",
    "        i+= 1\n",
    "    get_error(y_pred, y_test)\n",
    "    #print(\"\\nAVERAGE R**2 score: \", score_sum / K)\n",
    "    return returns\n",
    "\n",
    "def run_approach1v2(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    \n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, hour_of_day.shape[1] + days_of_week.shape[1] + 6 \\\n",
    "                + 0 * NUM_STATIONS \\\n",
    "               ), 0, dtype=np.float)\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 0:7]= day_of_week\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 7:31]= hour_of_day\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 31:32]= scld_fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index + 1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 32:33]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 33:34]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 1:2]), (TOTAL_TIME_DATAPOINTS, 1)) # past10\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 34:35]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 2:3]), (TOTAL_TIME_DATAPOINTS, 1)) # past15\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 35:36]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 3:4]), (TOTAL_TIME_DATAPOINTS, 1)) # past20\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 36:37]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 4:5]), (TOTAL_TIME_DATAPOINTS, 1)) # past25\n",
    "\n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    returns= []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        regr= MLPRegressor(random_state= 1, max_iter= 1000, alpha=0.001).fit(X_train, y_train)\n",
    "        y_pred= regr.predict(X_test)\n",
    "        score_sum+= regr.score(X_test, y_test)\n",
    "        returns.append(regr.score(X_test, y_test))\n",
    "        #print(\"R**2 score of data split\", i, \": \", regr.score(X_test, y_test))\n",
    "        i+= 1\n",
    "    get_error(y_pred, y_test)\n",
    "    #print(\"\\nAVERAGE R**2 score: \", score_sum / K)\n",
    "    return returns\n",
    "\n",
    "def run_approach1v3(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    \n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, hour_of_day.shape[1] + days_of_week.shape[1] + 2 \\\n",
    "                + 4 * NUM_STATIONS \\\n",
    "               ), 0, dtype=np.float)\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 0:7]= day_of_week\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 7:31]= hour_of_day\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 31:32]= scld_fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index + 1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 32:33]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index + 1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 33:141]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 1:2]), (TOTAL_TIME_DATAPOINTS, NUM_STATIONS)) # past10\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 141:249]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 2:3]), (TOTAL_TIME_DATAPOINTS, NUM_STATIONS)) # past15\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 249:357]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 3:4]), (TOTAL_TIME_DATAPOINTS, NUM_STATIONS)) # past20\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 357:465]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 4:5]), (TOTAL_TIME_DATAPOINTS, NUM_STATIONS)) # past25\n",
    "\n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    returns= []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        regr= MLPRegressor(random_state= 1, max_iter= 1000, alpha=0.001).fit(X_train, y_train)\n",
    "        y_pred= regr.predict(X_test)\n",
    "        score_sum+= regr.score(X_test, y_test)\n",
    "        returns.append(regr.score(X_test, y_test))\n",
    "        #print(\"R**2 score of data split\", i, \": \", regr.score(X_test, y_test))\n",
    "        i+= 1\n",
    "    get_error(y_pred, y_test)\n",
    "    #print(\"\\nAVERAGE R**2 score: \", score_sum / K)\n",
    "    return returns\n",
    "    \n",
    "def run_approach2(station_name, neighs= OPTIMAL_NEIGHBOURS):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    \n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, 2 + 3 \\\n",
    "            #* bikes_changes_pastx.shape[1] \\ # This line is uncommented when training on all stations\n",
    "           ), -1, dtype=np.float)\n",
    "    \n",
    "    positions= []; t= 0\n",
    "    while t < 2 * math.pi:\n",
    "        positions.append((1 - (R * math.cos(t) + R), R * math.sin(t) + R))\n",
    "        t+= STEP_SIZE\n",
    "    pos_i= 0\n",
    "    for time_i in range(TOTAL_TIME_DATAPOINTS):\n",
    "        X[time_i, 0]= positions[pos_i][0]\n",
    "        X[time_i, 1]= positions[pos_i][1]\n",
    "        pos_i= (pos_i + 1) % len(positions)\n",
    "    \n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 2:3]= scld_fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index+1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 3:4]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 4:5]= np.reshape((scld_bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 1:2]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 2:110]= bikes_changes_past5\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 110:218]= bikes_changes_past15\n",
    "    \n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    returns= []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        neigh= KNeighborsRegressor(n_neighbors= neighs, weights='distance').fit(X_train, y_train)\n",
    "        y_pred= neigh.predict(X_test)\n",
    "        score_sum+= neigh.score(X_test, y_test)\n",
    "        returns.append(neigh.score(X_test, y_test))\n",
    "        #print(\"R**2 score of data split\", i, \": \", regr.score(X_test, y_test))\n",
    "        i+= 1\n",
    "    get_error(y_pred, y_test)\n",
    "    #print(\"\\nAVERAGE R**2 score: \", score_sum / K)\n",
    "    return returns\n",
    "\n",
    "def run_oldbaseline(station_name, regulariser_coef):\n",
    "    index= get_station_id(station_name)\n",
    "    max_train_time= DATAPOINTS_PER_DAY * DAYS_PER_WEEKDAY * len(DAYS_OF_WEEK)\n",
    "    y_test= np.reshape(fullness[max_train_time:TOTAL_TIME_DATAPOINTS, index:index+1], TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    y_pred= np.zeros(TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    for i in range(int((TOTAL_TIME_DATAPOINTS - max_train_time) / DATAPOINTS_PER_DAY)):\n",
    "        datapoint_i= i * DATAPOINTS_PER_DAY\n",
    "        day_of_week_i= int((max_train_time + datapoint_i) / DATAPOINTS_PER_DAY) % len(DAYS_OF_WEEK)\n",
    "        y_pred[datapoint_i:datapoint_i + DATAPOINTS_PER_DAY]= (np.reshape(average_weekday_fullness[0:DATAPOINTS_PER_DAY, index:index+1, day_of_week_i:day_of_week_i+1], DATAPOINTS_PER_DAY) * (1 - regulariser_coef) + np.full(DATAPOINTS_PER_DAY, avrg_weekday_full[index:index+1, day_of_week_i:day_of_week_i+1]) * regulariser_coef)\n",
    "    #print(\"R**2 score: \", r2_score(y_test, y_pred))\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "def run_meanline(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    max_train_time= DATAPOINTS_PER_DAY * DAYS_PER_WEEKDAY * len(DAYS_OF_WEEK)\n",
    "    y_test= np.reshape(fullness[max_train_time:TOTAL_TIME_DATAPOINTS, index:index+1], TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    y_pred= np.zeros(TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    for i in range(int((TOTAL_TIME_DATAPOINTS - max_train_time) / DATAPOINTS_PER_DAY)):\n",
    "        datapoint_i= i * DATAPOINTS_PER_DAY\n",
    "        day_of_week_i= int((max_train_time + datapoint_i) / DATAPOINTS_PER_DAY) % len(DAYS_OF_WEEK)\n",
    "        y_pred[datapoint_i:datapoint_i + DATAPOINTS_PER_DAY]= np.full(DATAPOINTS_PER_DAY, meanmean[index:index+1], dtype=np.float64)\n",
    "    #print(\"R**2 score: \", r2_score(y_test, y_pred))\n",
    "    return r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_graph():\n",
    "    meanmean1= run_meanline(\"PORTOBELLO ROAD\")\n",
    "    meanmean2= run_meanline(\"CUSTOM HOUSE QUAY\")\n",
    "    coefs= np.linspace(0, 1, num=30)\n",
    "    \n",
    "    s1_r2= []\n",
    "    s2_r2= []\n",
    "    s1_r2meanmean= []\n",
    "    s2_r2meanmean= []\n",
    "\n",
    "    for coef in coefs:\n",
    "        s1_r2.append(run_oldbaseline(\"PORTOBELLO ROAD\", coef))\n",
    "        s2_r2.append(run_oldbaseline(\"CUSTOM HOUSE QUAY\", coef))\n",
    "        s1_r2meanmean.append(meanmean1)\n",
    "        s2_r2meanmean.append(meanmean2)\n",
    "\n",
    "    ax= plt.gca()\n",
    "\n",
    "    ax.plot(coefs, s1_r2, label=\"Portobello Road (baseline)\", color=\"#F28C28\")\n",
    "    ax.plot(coefs, s1_r2meanmean, label=\"Portobello Road (mean)\", color=\"#FAD5A5\")\n",
    "    ax.plot(coefs, s2_r2, label=\"Custom House Quay (baseline)\", color=\"#0047AB\")\n",
    "    ax.plot(coefs, s2_r2meanmean, label=\"Custom House Quay (mean)\", color=\"#A7C7E7\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.xlabel('Baseline\\'s coefficent for homemade regulariser')\n",
    "    plt.ylabel('R**2 score')\n",
    "    plt.title('Baseline model')\n",
    "    plt.show()\n",
    "    \n",
    "def neighbours_optimisation(station_name1, station_name2):\n",
    "    xs= [int(x) for x in np.linspace(1, 100, num=20)]\n",
    "    y1s= []; y2s= []\n",
    "    for x in xs:\n",
    "        returns= run_approach2(station_name1, x)\n",
    "        y1s.append(sum(returns) / len(returns))\n",
    "        returns= run_approach2(station_name2, x)\n",
    "        y2s.append(sum(returns) / len(returns))\n",
    "    ax= plt.gca()\n",
    "    \n",
    "    ax.plot(xs, y1s, label=station_name1, color=\"#F28C28\")\n",
    "    ax.plot(xs, y2s, label=station_name2, color=\"#0047AB\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.xlabel('Number of neighbours')\n",
    "    plt.ylabel('R**2 score')\n",
    "    plt.title('Optimising n_neighbours')\n",
    "    plt.show()\n",
    "\n",
    "def compare_approaches(station_name1, station_name2, approach1, approach2, approach3=None):\n",
    "    s1a1_r2s= []; s2a1_r2s= []; s1a2_r2s= []; s2a2_r2s= []; s1a3_r2s= []; s2a3_r2s= []\n",
    "    \n",
    "    val= [0.8544876302212273, 0.9103206998138718, 0.9156765327292385, 0.9162074563960463, 0.9386270881532218]#approach1(station_name1) #[0.9154489426476711, 0.9321981853574037, 0.9033862664158813, 0.8607531451151377, 0.8425975287920906]#approach1(station_name1)\n",
    "    print(\"approach1(station_name1):\", val)\n",
    "    if type(val) is list:\n",
    "        s1a1_r2s= sorted(val)\n",
    "    else:\n",
    "        s1a1_r2s.append(val); s1a1_r2s.append(val); s1a1_r2s.append(val); s1a1_r2s.append(val); s1a1_r2s.append(val)\n",
    "    \n",
    "    val= [0.795526303673726, 0.8143441006746407, 0.8204766460302203, 0.8615393834469698, 0.788609683100724]#approach1(station_name2) #[0.77629295945547, 0.7949464686296777, 0.7967860515294295, 0.8358203281148665, 0.8471048354650209]#approach1(station_name2)\n",
    "    print(\"approach1(station_name2):\", val)\n",
    "    if type(val) is list:\n",
    "        s2a1_r2s= sorted(val)\n",
    "    else:\n",
    "        s2a1_r2s.append(val); s2a1_r2s.append(val); s2a1_r2s.append(val); s2a1_r2s.append(val); s2a1_r2s.append(val)\n",
    "#########################################################################################################\n",
    "    val= [0.9190271650242875, 0.9420657457918499, 0.9146759986093368, 0.917653317897591, 0.8564092920020631]#approach2(station_name1)\n",
    "    print(\"approach2(station_name1):\", val)\n",
    "    if type(val) is list:\n",
    "        s1a2_r2s= sorted(val)\n",
    "    else:\n",
    "        s1a2_r2s.append(val); s1a2_r2s.append(val); s1a2_r2s.append(val); s1a2_r2s.append(val); s1a2_r2s.append(val)\n",
    "    \n",
    "    val= [0.7972544574987751, 0.8143952998700232, 0.8189551156559984, 0.8623204399472701, 0.7940865400569425]#approach2(station_name2)\n",
    "    print(\"approach2(station_name2):\", val)\n",
    "    if type(val) is list:\n",
    "        s2a2_r2s= sorted(val)\n",
    "    else:\n",
    "        s2a2_r2s.append(val); s2a2_r2s.append(val); s2a2_r2s.append(val); s2a2_r2s.append(val); s2a2_r2s.append(val)\n",
    "#########################################################################################################\n",
    "    if approach3 != None:\n",
    "        val= [0.8701196589704495, 0.9032181011324892, 0.8744269239638829, 0.8873912710329473, 0.843289038452534]#approach3(station_name1)\n",
    "        print(\"approach3(station_name1):\", val)\n",
    "        if type(val) is list:\n",
    "            s1a3_r2s= sorted(val)\n",
    "        else:\n",
    "            s1a3_r2s.append(val); s1a3_r2s.append(val); s1a3_r2s.append(val); s1a3_r2s.append(val); s1a3_r2s.append(val)\n",
    "\n",
    "        val= [0.6209740089315421, 0.7218889672070009, 0.7274194072782662, 0.7765443329528768, 0.7200027086352144]#approach3(station_name2)\n",
    "        print(\"approach3(station_name2):\", val)\n",
    "        if type(val) is list:\n",
    "            s2a3_r2s= sorted(val)\n",
    "        else:\n",
    "            s2a3_r2s.append(val); s2a3_r2s.append(val); s2a3_r2s.append(val); s2a3_r2s.append(val); s2a3_r2s.append(val)\n",
    "    \n",
    "    print(\"s1a1_r2s:\", s1a1_r2s)\n",
    "    print(\"s2a1_r2s:\", s2a1_r2s)\n",
    "    print(\"s1a2_r2s:\", s1a2_r2s)\n",
    "    print(\"s2a2_r2s:\", s2a2_r2s)\n",
    "    if approach3 != None:\n",
    "        print(\"s1a3_r2s:\", s1a3_r2s)\n",
    "        print(\"s2a3_r2s:\", s2a3_r2s)\n",
    "    \n",
    "    x= np.linspace(1, 5, num=K, dtype=np.int)\n",
    "    \n",
    "    ax= plt.gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    ax.plot(x, s1a1_r2s, label=\"Portobello Road; Approach 1\", color=\"#F28C28\")\n",
    "    ax.plot(x, s2a1_r2s, label=\"Custom House Quay; Approach 1\", color=\"#FAD5A5\")\n",
    "    ax.plot(x, s1a2_r2s, label=\"Portobello Road; Approach 1v2\", color=\"#0047AB\")\n",
    "    ax.plot(x, s2a2_r2s, label=\"Custom House Quay; Approach 1v2\", color=\"#A7C7E7\")\n",
    "    if approach3 != None:\n",
    "        ax.plot(x, s1a3_r2s, label=\"Portobello Road; Approach 1v3\", color=\"#026420\")\n",
    "        ax.plot(x, s2a3_r2s, label=\"Custom House Quay; Approach 1v3\", color=\"#92CA91\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.xlabel('Kth Fold')\n",
    "    plt.ylabel('R**2 Score')\n",
    "    plt.title('Approach Comparison')\n",
    "    plt.show()\n",
    "\n",
    "def error_histo():\n",
    "    x= []\n",
    "    x2= []\n",
    "    for e_i, e in enumerate(errors[0]):\n",
    "        for n in range(e.astype(int).item()):\n",
    "            x.append(e_i + 1)\n",
    "    for e_i, e in enumerate(errors[1]):\n",
    "        for n in range(e.astype(int).item()):\n",
    "            x2.append(e_i + 1)\n",
    "    \n",
    "    n_bins= MAX_ERROR_DIFF\n",
    "    \n",
    "    fig, axs= plt.subplots(1, 2, sharey=True, sharex=True, tight_layout=True)\n",
    "\n",
    "    # We can set the number of bins with the `bins` kwarg\n",
    "    axs[0].hist(x, bins= n_bins)\n",
    "    axs[0].set(xlabel='Error size (in bikes)', ylabel='Error frequency')\n",
    "    axs[0].set_title('Approach 1; Portobello Road')\n",
    "    axs[1].hist(x2, bins= n_bins)\n",
    "    axs[1].set(xlabel='Error size (in bikes)', ylabel='Error frequency')\n",
    "    axs[1].set_title('Approach 2; Portobello Road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DRIVER\n",
    "errors= np.zeros((3, MAX_ERROR_DIFF), dtype=np.int)\n",
    "run_approach1(\"PORTOBELLO ROAD\")\n",
    "run_approach2(\"PORTOBELLO ROAD\")\n",
    "error_histo()\n",
    "\n",
    "# neighbours_optimisation(\"PORTOBELLO ROAD\", \"CUSTOM HOUSE QUAY\")\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
