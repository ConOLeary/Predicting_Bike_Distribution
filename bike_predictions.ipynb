{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS & DEFINITIONS\n",
    "\n",
    "import csv, sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np; np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "DUD_VALUE= 0 # change from 0 to something like 123 for debugging\n",
    "EMPTY_DATA_DAY_VAL= 123456789\n",
    "TOTAL_ROWS= 9999999999\n",
    "INPUT_ROWS_LIMIT= TOTAL_ROWS # 500000\n",
    "FILENAME= 'dublinbikes_2020_Q1.csv'\n",
    "MAX_STATIONS= 118\n",
    "SECS_IN_5MIN= 300\n",
    "DATAPOINT_EVERYX_MIN= 5\n",
    "DATAPOINTS_PER_DAY= 288\n",
    "DAYS_OF_WEEK= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] # yes, I consider Monday to be the '0'/start of the week\n",
    "STARTING_DATE= 0 # aka Monday. Because the 27th of Jan 2020 is a Monday\n",
    "MISSING_STATIONS= [117, 116, 70, 60, 46, 35, 20, 14, 1, 0]\n",
    "NUM_STATIONS= MAX_STATIONS - len(MISSING_STATIONS)\n",
    "SUBSTANDARD_DAYS= [] # [50, 49]\n",
    "TOTAL_DAYS= 66 # from 27 / 1 / 2020 to (and including) 1 / 4 / 2020\n",
    "HOURS= 24\n",
    "EPOCH= datetime.datetime(2020, 1, 27, 0, 0)\n",
    "TOTAL_TIME_DATAPOINTS= int((datetime.datetime(2020,4,2,0,0) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "K= 5\n",
    "STEP_SIZE= 0.02185 # just the magic number that leads to 288 values being generated\n",
    "R= 0.5\n",
    "MAX_HINDSIGHT= 60 # minutes\n",
    "DAYS_PER_WEEKDAY= 5\n",
    "HOMEMADE_REGULISER= 0.8\n",
    "\n",
    "class DataDay: # ideally this would be nested in the Station class\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.substandard_day= False\n",
    "        if index in SUBSTANDARD_DAYS:\n",
    "            self.substandard_day= True\n",
    "        self.times_populated= 0\n",
    "        self.day_of_week= ((STARTING_DATE + index) % len(DAYS_OF_WEEK))\n",
    "        \n",
    "        self.daily_epoch_time= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.epoch_time= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.bikes= np.full(DATAPOINTS_PER_DAY, EMPTY_DATA_DAY_VAL, dtype=np.int)\n",
    "        self.percent_bikes= np.full(DATAPOINTS_PER_DAY, float(EMPTY_DATA_DAY_VAL), dtype=np.float)\n",
    "\n",
    "    def populate(self, daily_epoch_time, epoch_time, bikes, percent_bikes):\n",
    "        if self.substandard_day == False:\n",
    "            self.daily_epoch_time[daily_epoch_time]= daily_epoch_time\n",
    "            self.epoch_time[daily_epoch_time]= epoch_time\n",
    "            self.bikes[daily_epoch_time]= bikes\n",
    "            self.percent_bikes[daily_epoch_time]= percent_bikes\n",
    "            self.times_populated+= 1\n",
    "\n",
    "class Station:\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.name= DUD_VALUE\n",
    "        self.bike_capacity= DUD_VALUE\n",
    "        self.address= DUD_VALUE\n",
    "        self.latitude= DUD_VALUE\n",
    "        self.longitude= DUD_VALUE\n",
    "        self.data_days= [DataDay(i) for i in range(0, TOTAL_DAYS)]\n",
    "    \n",
    "    def populate_consts(self, name, bike_capacity, address, latitude, longitude):\n",
    "        self.name= name\n",
    "        self.bike_capacity= bike_capacity\n",
    "        self.address= address\n",
    "        self.latitude= latitude\n",
    "        self.longitude= longitude\n",
    "\n",
    "def get_station_id(name):\n",
    "    try:\n",
    "        index= [x.name for x in stations].index(name)\n",
    "    except ValueError:\n",
    "        index= -1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA STRUCTURING\n",
    "\n",
    "total_capacity= 0 # not in use currently\n",
    "index= []; daily_epoch_time= []; epoch_time= []; percent_bikes= [];\n",
    "stations= [Station(i) for i in range(0, MAX_STATIONS)]\n",
    "indices_to_populate= list(range(0, MAX_STATIONS))\n",
    "for index in MISSING_STATIONS:\n",
    "    indices_to_populate.remove(index)\n",
    "\n",
    "with open(FILENAME, newline='') as f:\n",
    "    reader = csv.reader(f); next(reader) # skip data header\n",
    "    current_index= 0\n",
    "    try:\n",
    "        while len(indices_to_populate) != 0:\n",
    "            row= next(reader)\n",
    "            if int(row[0]) == current_index: # this clause is just for performance\n",
    "                continue\n",
    "            current_index= int(row[0])\n",
    "            if current_index in indices_to_populate:\n",
    "                stations[current_index].populate_consts(row[3], row[4], row[8], row[9], row[10])\n",
    "                indices_to_populate.remove(current_index)\n",
    "                total_capacity+= int(row[4])\n",
    "        \n",
    "        f.seek(0)\n",
    "        reader= csv.reader(f); row= next(reader) # skip data header\n",
    "        for row_i, row in enumerate(reader):\n",
    "            if row_i >= INPUT_ROWS_LIMIT:\n",
    "                break\n",
    "            if int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds()) < 0:\n",
    "                continue\n",
    "            try:\n",
    "                epoch_time= int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "                stations[int(row[0])].data_days[int(epoch_time / DATAPOINTS_PER_DAY)].populate( \\\n",
    "                    int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), 0, 0)).total_seconds() / (SECS_IN_5MIN)), \\\n",
    "                    epoch_time, \\\n",
    "                    int(row[6]), \\\n",
    "                    float(\"{:.3f}\".format(float(row[6]) / float(row[4]))))\n",
    "            except IndexError as e:\n",
    "                print(\"Error:\", e, int(row[0]))\n",
    "                #print(\"\\nTRIED: \", epoch_time, ' / ', DATAPOINTS_PER_DAY, ' = ', int(epoch_time / DATAPOINTS_PER_DAY))\n",
    "                #print(row[1])\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))\n",
    "            \n",
    "for station_i, station in enumerate(stations):\n",
    "    last_bikes= 0\n",
    "    last_percent_bikes= 0\n",
    "    for day_i, data_day in enumerate(station.data_days):\n",
    "        for val_i, val in enumerate(data_day.bikes):\n",
    "            if val == EMPTY_DATA_DAY_VAL:\n",
    "                stations[station_i].data_days[day_i].populate(val_i, day_i * DATAPOINTS_PER_DAY + val_i, last_bikes, last_percent_bikes)\n",
    "            else:\n",
    "                last_bikes= data_day.bikes[val_i]\n",
    "                last_percent_bikes= data_day.percent_bikes[val_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.25694444  4.97777778  7.6625      6.93055556  4.75833333  3.58194444\n",
      "   2.87152778]\n",
      " [ 3.51458333  2.43333333  4.42777778  4.775       5.00138889  6.73611111\n",
      "   4.81736111]\n",
      " [ 4.58125     4.77291667  6.25763889  6.65208333  5.44722222  8.29444444\n",
      "  11.78194444]\n",
      " [15.63472222 18.17638889 19.89652778 15.35208333 11.9875     14.65486111\n",
      "  15.02013889]\n",
      " [ 3.00208333  1.37222222  1.14375     1.87777778  3.84166667 10.57638889\n",
      "  13.95625   ]\n",
      " [ 7.94027778  9.14097222  5.23611111  5.72222222  8.01805556 12.07916667\n",
      "  11.49236111]\n",
      " [ 9.64166667 10.71180556 11.64791667  8.62847222 13.97916667 14.80138889\n",
      "  11.23472222]\n",
      " [ 7.68958333  8.15416667  7.89722222  8.96805556 12.63888889 13.69305556\n",
      "  12.74513889]\n",
      " [ 4.21597222  5.81458333  5.09444444  6.55        8.92430556 11.52361111\n",
      "  11.94513889]\n",
      " [ 7.50625     8.44513889  6.67222222  6.05555556  6.77569444  1.53680556\n",
      "   2.72361111]\n",
      " [ 5.27986111  7.09652778  7.95138889  8.87986111  7.65902778  4.71597222\n",
      "   4.99236111]\n",
      " [ 8.66597222  9.43263889  8.84861111  8.65486111  7.28958333  2.01041667\n",
      "   4.60208333]\n",
      " [ 2.10208333  2.90277778  3.68125     3.45833333  2.50625     2.15416667\n",
      "   2.02777778]\n",
      " [ 8.5125      4.96388889  6.73125     6.19027778  8.06527778 13.11458333\n",
      "  11.80763889]\n",
      " [ 5.93958333  1.46319444  1.99305556  2.53541667  3.81597222  8.34444444\n",
      "  11.58888889]\n",
      " [ 8.09305556  6.74722222  6.9125      6.28611111  5.00902778  5.01388889\n",
      "  10.94027778]\n",
      " [ 8.84722222 10.07361111  8.84791667  9.69444444  9.34513889  9.99236111\n",
      "  10.18055556]\n",
      " [12.03472222  9.37916667 10.99375     9.51388889 12.59236111 11.85138889\n",
      "  13.84375   ]\n",
      " [ 5.86041667  6.01875     7.24236111  7.79236111  9.34513889 10.18194444\n",
      "   9.40625   ]\n",
      " [10.30833333 11.73680556  9.84375    11.40138889 13.60347222 18.34930556\n",
      "  17.4125    ]\n",
      " [ 3.62152778  5.66041667  7.06597222  6.74930556  7.42430556 15.08888889\n",
      "   9.425     ]\n",
      " [10.77361111  9.40694444 10.41944444 11.30138889 10.86041667  3.71388889\n",
      "   5.41666667]\n",
      " [10.16458333  7.54444444  7.51597222  7.63958333  8.37638889  8.05833333\n",
      "  13.68541667]\n",
      " [ 5.21875     5.67847222  4.76388889  5.30972222  6.15138889  8.51875\n",
      "   9.66180556]\n",
      " [ 8.63611111 14.54305556 15.48333333 14.26944444 13.625      13.00763889\n",
      "   7.57777778]\n",
      " [ 5.75416667  5.63055556  5.68055556  6.42291667 11.34305556 22.05763889\n",
      "  21.40625   ]\n",
      " [ 1.82847222  3.23611111  3.87430556  4.63333333  2.09305556  2.025\n",
      "   1.80625   ]\n",
      " [ 3.32847222  5.30416667  6.7375      6.73958333  7.01458333 11.96666667\n",
      "   8.56111111]\n",
      " [ 7.59652778  7.59791667  8.3125      8.52777778 10.40069444 14.03888889\n",
      "  13.32361111]\n",
      " [ 7.375      11.05069444 10.88541667 10.56875    12.61875    17.24027778\n",
      "  13.475     ]\n",
      " [12.09375    15.20069444 13.81666667 13.36736111 14.06944444 12.98888889\n",
      "  11.43888889]\n",
      " [14.95694444 12.23472222 11.91041667 12.23333333 10.90347222  9.30416667\n",
      "  13.53541667]\n",
      " [ 5.66597222  3.62222222  3.31458333  3.46736111  4.88611111  4.65\n",
      "   8.1625    ]\n",
      " [14.87013889 21.2625     21.99097222 17.56180556 22.70833333 30.59583333\n",
      "  26.39722222]\n",
      " [ 3.58402778  3.42152778  3.13888889  4.74305556  2.62638889  5.40833333\n",
      "   5.99305556]\n",
      " [ 4.90763889  3.57291667  3.30625     4.37847222  7.42013889 12.84583333\n",
      "  12.30416667]\n",
      " [ 3.51666667  4.63611111  4.65347222  2.90347222  3.21041667  1.68263889\n",
      "   2.1875    ]\n",
      " [13.23611111 14.92569444 16.94444444 15.48263889 16.24375    21.99513889\n",
      "  22.88472222]\n",
      " [10.42152778 15.04166667 15.46666667 12.32569444 13.3875     14.70833333\n",
      "  10.26458333]\n",
      " [13.25763889 16.35138889 16.19166667 16.88611111 16.25763889 15.86111111\n",
      "  11.25138889]\n",
      " [14.06180556 15.89444444 16.80833333 12.97777778 14.76041667 22.85555556\n",
      "  25.76666667]\n",
      " [12.46944444 12.37430556 12.41527778 12.8125     11.64027778  3.07638889\n",
      "   3.65416667]\n",
      " [16.74861111 15.05208333 16.85763889 14.40416667 15.73402778 13.17569444\n",
      "  15.59930556]\n",
      " [15.625      15.98125    13.04444444 14.45486111 21.11319444 12.82291667\n",
      "  11.34652778]\n",
      " [ 8.70833333 14.31944444 17.91458333 15.76111111 13.89027778 16.39375\n",
      "  14.30486111]\n",
      " [10.27083333  5.72430556  4.10208333  5.22986111  6.925      15.28333333\n",
      "  23.27152778]\n",
      " [ 8.28958333  5.04861111  4.94791667  5.01944444  7.72569444 11.30416667\n",
      "  15.95763889]\n",
      " [14.12986111  9.49097222 11.30208333 10.64861111 11.30763889  4.12777778\n",
      "   8.41111111]\n",
      " [13.42152778  7.29930556  5.72638889  6.30208333  6.21319444  5.75138889\n",
      "  12.84861111]\n",
      " [ 9.89097222  9.44583333  9.40138889  9.69652778  8.38333333  1.59513889\n",
      "   4.18472222]\n",
      " [15.31527778 15.35833333 13.24930556 16.64166667 12.43680556  8.21805556\n",
      "  13.09097222]\n",
      " [10.50555556  9.82777778  9.17430556 10.29027778  9.67847222  4.57152778\n",
      "   5.56805556]\n",
      " [15.83888889 15.3875     14.09305556 15.24513889 13.13958333  8.83958333\n",
      "  12.17569444]\n",
      " [ 2.85069444  4.35347222  2.83402778  4.28888889  5.32222222  3.80486111\n",
      "   1.64791667]\n",
      " [ 6.12430556  7.68958333  8.07083333  7.56180556  7.08263889 10.37708333\n",
      "   7.26736111]\n",
      " [14.19166667 13.37708333 13.07152778 12.65625    12.49583333  2.5375\n",
      "   5.34652778]\n",
      " [14.80277778 11.29097222 10.11388889 11.96458333 11.12152778 10.37916667\n",
      "  12.43680556]\n",
      " [17.32152778 13.34652778 12.31388889 12.40069444 14.81180556 12.09375\n",
      "  15.68402778]\n",
      " [11.42708333 11.7375      8.20347222 11.08819444 14.88958333  6.32638889\n",
      "   6.07361111]\n",
      " [14.8625     16.84097222 13.00208333 16.31805556 14.59375     8.20902778\n",
      "  14.36736111]\n",
      " [22.28611111 20.53263889 17.04097222 20.92708333 20.44444444 23.89583333\n",
      "  23.53402778]\n",
      " [14.80902778 13.40555556 13.18333333 14.97291667 14.13611111  5.66180556\n",
      "  12.98125   ]\n",
      " [20.77222222 16.37708333 14.67916667 16.33680556 15.97083333 12.81111111\n",
      "  18.95208333]\n",
      " [ 5.80972222  3.26597222  2.71111111  2.85694444  4.25416667 10.99652778\n",
      "  14.61527778]\n",
      " [10.1625     14.79027778 14.77569444 14.55416667 11.96597222 15.19861111\n",
      "  15.92569444]\n",
      " [ 8.5375      9.64930556  9.13055556  8.75625     7.57361111  8.51736111\n",
      "  11.52777778]\n",
      " [12.12708333 15.07638889 13.55069444 12.95486111 12.72152778 15.60694444\n",
      "  16.36458333]\n",
      " [11.4375     21.00208333 20.85694444 19.50625    20.11180556 18.71875\n",
      "  12.17916667]\n",
      " [12.87638889 21.96388889 19.56666667 17.40138889 17.97916667 15.30347222\n",
      "  11.41944444]\n",
      " [ 7.31805556  4.02083333  2.84027778  3.48263889  5.71111111 15.31527778\n",
      "  18.825     ]\n",
      " [15.16388889 20.72708333 22.46666667 22.0875     20.54583333 18.49305556\n",
      "  12.70416667]\n",
      " [ 4.16458333  6.13958333  6.00486111  7.8375     10.05347222  8.28263889\n",
      "   9.91111111]\n",
      " [11.19652778 15.90138889 17.91944444 18.45416667 15.99722222 17.98194444\n",
      "  14.88125   ]\n",
      " [ 7.43125    13.00277778 16.04513889 11.51805556 16.11111111 16.45763889\n",
      "  14.93611111]\n",
      " [ 5.25486111 11.42291667 11.30972222 10.77847222 10.38958333 10.25208333\n",
      "   4.58680556]\n",
      " [10.60486111 17.18958333 21.80208333 18.45902778 16.54375    17.61805556\n",
      "  15.68194444]\n",
      " [11.68333333 14.775      14.77569444 14.39930556 15.03611111 15.92986111\n",
      "  13.55138889]\n",
      " [10.43263889 17.175      17.12013889 13.81666667 13.61180556 15.8375\n",
      "   9.66666667]\n",
      " [13.47708333 20.03611111 20.02222222 20.44791667 18.525      28.06111111\n",
      "  22.70972222]\n",
      " [11.01527778 15.1875     15.47638889 16.32777778 13.35763889 15.65347222\n",
      "  15.89791667]\n",
      " [10.06944444 13.04722222 13.16041667 16.17291667 12.15138889 17.35416667\n",
      "  18.59791667]\n",
      " [10.35416667  9.12638889  7.43611111  9.65486111  8.27916667  4.10277778\n",
      "   4.10416667]\n",
      " [13.02291667 12.8375     13.91875    12.76736111 12.19444444  7.17083333\n",
      "   7.03958333]\n",
      " [16.28333333 16.73958333 15.84861111 17.21666667 14.37083333 23.43819444\n",
      "  17.78194444]\n",
      " [15.58194444 20.97013889 20.82638889 22.84652778 24.45416667 35.53402778\n",
      "  29.18125   ]\n",
      " [20.97569444 24.24513889 23.76041667 23.24791667 24.18611111 38.01875\n",
      "  37.39305556]\n",
      " [18.25555556 23.41805556 22.97708333 22.38125    23.58472222 29.90763889\n",
      "  32.40902778]\n",
      " [10.9875     17.65277778 19.46736111 17.55555556 16.01666667 12.97638889\n",
      "   7.44236111]\n",
      " [ 3.18541667  6.98402778  7.50902778  8.075       6.85347222  5.25069444\n",
      "   2.52291667]\n",
      " [ 9.74722222 15.66805556 14.81875    14.13263889 14.03611111 14.65208333\n",
      "  11.52083333]\n",
      " [11.65069444  9.04791667  6.69791667  5.18055556  8.37152778 10.08958333\n",
      "  14.59375   ]\n",
      " [13.7        10.40625     9.91527778 10.38194444 12.25694444  6.73194444\n",
      "   8.97986111]\n",
      " [ 8.03472222 13.6375     14.07222222 14.20902778 16.37430556 21.73263889\n",
      "  14.99513889]\n",
      " [ 7.25416667  9.80902778  9.75069444 11.46597222 11.66666667  8.23333333\n",
      "   9.20625   ]\n",
      " [ 6.63194444 11.72569444 12.48888889  9.80972222  8.23125    11.32291667\n",
      "   7.94583333]\n",
      " [ 5.03472222  6.77291667  5.13541667  5.68263889  3.14305556  2.77430556\n",
      "   5.04444444]\n",
      " [ 5.22291667  5.94930556  6.14166667  8.05416667  7.53333333  3.7625\n",
      "   4.48680556]\n",
      " [ 3.73541667  2.41597222  4.04375     4.44652778  5.69513889  8.88819444\n",
      "   6.42361111]\n",
      " [ 6.63541667 10.49027778 12.32430556 11.11805556 14.03611111  9.36180556\n",
      "   9.80138889]\n",
      " [15.63541667 17.31041667 14.51875    13.77083333 15.84722222 11.97222222\n",
      "  13.29444444]\n",
      " [ 9.32083333  9.57013889 12.10277778 11.96111111 10.45416667  8.61736111\n",
      "  11.52291667]\n",
      " [10.97916667 15.24861111 16.13402778 16.46458333 14.88819444 20.87847222\n",
      "  19.74652778]\n",
      " [ 6.95902778  6.21180556  8.55833333  9.89513889  9.48194444  8.82430556\n",
      "  10.34583333]\n",
      " [10.24027778 15.74652778 14.45138889 15.71458333 14.67083333 11.09305556\n",
      "   5.75625   ]\n",
      " [13.52638889 14.96319444 16.29791667 15.04236111 13.17361111 14.13680556\n",
      "  13.37291667]\n",
      " [12.00972222 10.84375    12.35902778 13.78055556  9.41666667  1.4875\n",
      "   2.55486111]\n",
      " [11.13680556 12.11319444 10.12847222 11.69583333  8.71597222  7.56736111\n",
      "  11.1375    ]\n",
      " [15.35972222 16.38055556 18.21597222 16.19583333 15.54027778 22.13194444\n",
      "  20.75069444]]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE DATA PREPERATION\n",
    "\n",
    "fullness= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_in10= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_in30= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_in60= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.int)\n",
    "fullness_percent= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS), DUD_VALUE, dtype=np.float)\n",
    "bikes_changes_pastx= np.full((TOTAL_TIME_DATAPOINTS, NUM_STATIONS, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), DUD_VALUE, dtype=np.int)\n",
    "days_of_week= np.full((TOTAL_TIME_DATAPOINTS, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.int)\n",
    "hour_of_day= np.full((TOTAL_TIME_DATAPOINTS, HOURS), DUD_VALUE, dtype=np.float)\n",
    "average_weekday_fullness= np.full((DATAPOINTS_PER_DAY, NUM_STATIONS, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.float)\n",
    "weekdays_vol= np.full((NUM_STATIONS, len(DAYS_OF_WEEK)), 0, dtype=np.float)\n",
    "avrg_weekday_full= np.full((NUM_STATIONS, len(DAYS_OF_WEEK)), 0, dtype=np.float)\n",
    "\n",
    "station_index_decrement= 0 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for epoch_day_i in range(TOTAL_DAYS):\n",
    "    #print(\"########### epoch_day_i: \", epoch_day_i)\n",
    "    x_offset= epoch_day_i * DATAPOINTS_PER_DAY\n",
    "    y_offset= 0\n",
    "    \n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, HOURS), dtype=np.float)\n",
    "    daily_epoch_time= list(range(DATAPOINTS_PER_DAY))\n",
    "    for time_i in daily_epoch_time:\n",
    "        hour= float(\"{:.3f}\".format(time_i / 12)) # divide by 12 because there are 12 datapoints in an hour\n",
    "        block[time_i][(int(hour) + 1) % HOURS]= hour % 1\n",
    "        block[time_i][int(hour)]= 1 - (hour % 1)\n",
    "    hour_of_day[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    day_of_week= stations[2].data_days[epoch_day_i].day_of_week\n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, len(DAYS_OF_WEEK)), dtype=np.int)\n",
    "    for block_i, sub_arr in enumerate(block):\n",
    "        block[block_i][day_of_week]= 1\n",
    "    days_of_week[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    for station in stations:\n",
    "        #print(\"###### station.index: \", station.index)\n",
    "        if station.index == 0:\n",
    "            station_index_decrement= 0\n",
    "        if station.index in MISSING_STATIONS:\n",
    "            station_index_decrement+= 1\n",
    "            continue\n",
    "        y_offset= station.index - station_index_decrement\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].percent_bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness_percent[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1, 1))\n",
    "        if weekdays_vol[y_offset, day_of_week] < DAYS_PER_WEEKDAY:\n",
    "            average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset + block.shape[1], day_of_week:day_of_week+1]+= block\n",
    "            weekdays_vol[y_offset:y_offset+1, day_of_week:day_of_week+1]+= 1\n",
    "        \n",
    "        bikes= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(bikes[2:], (bikes.shape[0] - 2, 1))\n",
    "        fullness_in10[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[6:], (bikes.shape[0] - 6, 1))\n",
    "        fullness_in30[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[12:], (bikes.shape[0] - 12, 1))\n",
    "        fullness_in60[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= np.reshape(station.data_days[epoch_day_i].bikes, (DATAPOINTS_PER_DAY, 1))\n",
    "        if epoch_day_i - 1 == -1:\n",
    "            prev_block= np.zeros((DATAPOINTS_PER_DAY, 1), dtype=np.int)\n",
    "        else:\n",
    "            prev_block= np.reshape(station.data_days[epoch_day_i - 1].bikes, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_xminchange= np.zeros((DATAPOINTS_PER_DAY, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), dtype=np.int)\n",
    "        fullness_xago= np.zeros((DATAPOINTS_PER_DAY, int(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN)), dtype=np.int)\n",
    "        for col_i in range(fullness_xago.shape[1]):\n",
    "            i= col_i + 1\n",
    "            fullness_xago[i:DATAPOINTS_PER_DAY, col_i:col_i + 1]= block[0:DATAPOINTS_PER_DAY - i, 0:1]\n",
    "            fullness_xago[0:i, col_i:col_i + 1]= prev_block[DATAPOINTS_PER_DAY - i:DATAPOINTS_PER_DAY, 0:1]\n",
    "        for col_i in range(fullness_xago.shape[1]):\n",
    "            block_xminchange[0:DATAPOINTS_PER_DAY, col_i:col_i + 1]= np.subtract(block, fullness_xago[0:DATAPOINTS_PER_DAY, col_i:col_i + 1])\n",
    "        \n",
    "        bikes_changes_pastx[x_offset:x_offset + block_xminchange.shape[0], y_offset:y_offset + 1, 0:block_xminchange.shape[1]]= np.reshape(block_xminchange, (DATAPOINTS_PER_DAY, 1, block_xminchange.shape[1]))\n",
    "\n",
    "station_index_decrement= 0 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for station in stations:\n",
    "    if station.index == 0: # [117, 116, 70, 60, 46, 35, 20, 14, 1, 0]\n",
    "        station_index_decrement= 0\n",
    "    if station.index in MISSING_STATIONS:\n",
    "        station_index_decrement+= 1\n",
    "        continue\n",
    "    y_offset= station.index - station_index_decrement\n",
    "    for day_of_week_i in range(len(DAYS_OF_WEEK)):\n",
    "        average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]/= weekdays_vol[y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]\n",
    "        avrg_weekday_full[y_offset:y_offset+1, day_of_week_i:day_of_week_i+1]= np.mean(average_weekday_fullness[0:DATAPOINTS_PER_DAY, y_offset:y_offset+1, day_of_week_i:day_of_week_i+1])\n",
    "\n",
    "print(avrg_weekday_full)\n",
    "# avrg_weekday_full= np.full((NUM_STATIONS, len(DAYS_OF_WEEK)), 0, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH DEFINITIONS\n",
    "    \n",
    "def run_approach1(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "\n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, hour_of_day.shape[1] + day_of_week.shape[1] + 3 \\\n",
    "                + 0 * NUM_STATIONS \\\n",
    "               ), 0, dtype=np.float)\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 0:7]= day_of_week\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 7:31]= hour_of_day\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 31:32]= fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index + 1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 32:33]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index + 1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 33:34]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index + 1, 1:2]), (TOTAL_TIME_DATAPOINTS, 1)) # past10\n",
    "    #X[0:TOTAL_TIME_DATAPOINTS, 34:35]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 2:3]), (TOTAL_TIME_DATAPOINTS, 1)) # past15\n",
    "    #X[0:TOTAL_TIME_DATAPOINTS, 35:36]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 3:4]), (TOTAL_TIME_DATAPOINTS, 1)) # past20\n",
    "    #X[0:TOTAL_TIME_DATAPOINTS, 36:37]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 4:5]), (TOTAL_TIME_DATAPOINTS, 1)) # past25\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 139:247]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 247:355]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 2:3]), (TOTAL_TIME_DATAPOINTS, 1)) # past15\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 355:463]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, 0:NUM_STATIONS, 8:9]), (TOTAL_TIME_DATAPOINTS, 1)) # past45\n",
    "\n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        regr= MLPRegressor(random_state= 1, max_iter= 1000, alpha=0.001).fit(X_train, y_train)\n",
    "        y_pred= regr.predict(X_test)\n",
    "        score_sum+= regr.score(X_test, y_test)\n",
    "        print(\"R**2 accuracy of data split\", i, \": \", regr.score(X_test, y_test) * 100, \" %\")\n",
    "        i+= 1\n",
    "    print(\"\\nAVERAGE R**2 evaluation: \", (score_sum / K) * 100, \" %\")\n",
    "    \n",
    "def run_approach2(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((TOTAL_TIME_DATAPOINTS, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 0:1]= np.reshape(fullness_in10[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 1:2]= np.reshape(fullness_in30[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    y[0:TOTAL_TIME_DATAPOINTS, 2:3]= np.reshape(fullness_in60[:,index], (TOTAL_TIME_DATAPOINTS, 1))\n",
    "    \n",
    "    X= np.full((TOTAL_TIME_DATAPOINTS, 2 + 2 \\\n",
    "            #* bikes_changes_pastx.shape[1] \\ # This line is uncommented when training on all stations\n",
    "           ), -1, dtype=np.float)\n",
    "    \n",
    "    positions= []; t= 0\n",
    "    while t < 2 * math.pi:\n",
    "        positions.append((1 - (R * math.cos(t) + R), R * math.sin(t) + R))\n",
    "        t+= STEP_SIZE\n",
    "    pos_i= 0\n",
    "    for time_i in range(TOTAL_TIME_DATAPOINTS):\n",
    "        X[time_i, 0]= positions[pos_i][0]\n",
    "        X[time_i, 1]= positions[pos_i][1]\n",
    "        pos_i= (pos_i + 1) % len(positions)\n",
    "    \n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 2:3]= fullness_percent[0:TOTAL_TIME_DATAPOINTS, index:index+1]\n",
    "    X[0:TOTAL_TIME_DATAPOINTS, 3:4]= np.reshape((bikes_changes_pastx[0:TOTAL_TIME_DATAPOINTS, index:index+1, 0:1]), (TOTAL_TIME_DATAPOINTS, 1)) # past5\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 2:110]= bikes_changes_past5\n",
    "    # X[0:TOTAL_TIME_DATAPOINTS, 110:218]= bikes_changes_past15\n",
    "    \n",
    "    neigh= KNeighborsRegressor(n_neighbors= 30, weights='distance')\n",
    "    cv_scores= cross_val_score(neigh, X, y, cv=5)\n",
    "    print(cv_scores) # print each cv score (accuracy) and average them\n",
    "    print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "\n",
    "def run_baseline(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    max_train_time= DATAPOINTS_PER_DAY * DAYS_PER_WEEKDAY * len(DAYS_OF_WEEK)\n",
    "    y_test= np.reshape(fullness[max_train_time:TOTAL_TIME_DATAPOINTS, index:index+1], TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    y_pred= np.zeros(TOTAL_TIME_DATAPOINTS - max_train_time)\n",
    "    for i in range(int((TOTAL_TIME_DATAPOINTS - max_train_time) / DATAPOINTS_PER_DAY)):\n",
    "        datapoint_i= i * DATAPOINTS_PER_DAY\n",
    "        day_of_week_i= int((max_train_time + datapoint_i) / DATAPOINTS_PER_DAY) % len(DAYS_OF_WEEK)\n",
    "        y_pred[datapoint_i:datapoint_i + DATAPOINTS_PER_DAY]= (np.reshape(average_weekday_fullness[0:DATAPOINTS_PER_DAY, index:index+1, day_of_week_i:day_of_week_i+1], DATAPOINTS_PER_DAY) * (1 - HOMEMADE_REGULISER) + np.full(DATAPOINTS_PER_DAY, avrg_weekday_full[index:index+1, day_of_week_i:day_of_week_i+1]) * HOMEMADE_REGULISER)\n",
    "#     for val_i in range(y_pred.shape[0]):\n",
    "#         print(\"y_test:\",y_test[val_i],\" y_pred:\",y_pred[val_i])\n",
    "    print(\"R**2 accuracy: \", r2_score(y_test, y_pred) * 100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R**2 accuracy:  -2.343928074188417  %\n",
      "--------------------\n",
      "R**2 accuracy:  -7.016015428461575  %\n"
     ]
    }
   ],
   "source": [
    "# DRIVER\n",
    "\n",
    "run_baseline(\"PORTOBELLO ROAD\")\n",
    "print(\"--------------------\")\n",
    "run_baseline(\"CUSTOM HOUSE QUAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
