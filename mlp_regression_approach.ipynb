{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np; np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "DUD_VALUE= 123\n",
    "TOTAL_ROWS= 2228278 # This number is greater than the total amount of rows circa epoch change to 27th, but it still works\n",
    "INPUT_ROWS_LIMIT= TOTAL_ROWS\n",
    "FILENAME= 'dublinbikes_2020_Q1.csv'\n",
    "MAX_STATION_ID= 117\n",
    "SECS_IN_5MIN= 300\n",
    "DATAPOINTS_PER_DAY= 288\n",
    "DAYS_OF_WEEK= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] # yes, I consider Monday to be the '0'/start of the week\n",
    "STARTING_DAY= 0 # aka Monday. Because the 27th of Jan 2020 is a Monday\n",
    "MISSING_STATIONS= [117, 116, 70, 60, 46, 35, 20, 14, 1]\n",
    "TOTAL_DAYS= 66 # from 27 / 1 / 2020 to (and including) 1 / 4 / 2020\n",
    "HOURS= 24\n",
    "EPOCH= datetime.datetime(2020, 1, 27, 0, 0)\n",
    "MAX_TIME= int((datetime.datetime(2020,4,2,0,0) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "DECREMENTS= 10\n",
    "\n",
    "class DataDay: # ideally this would be nested in the Station class\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.times_populated= 0\n",
    "        self.day_of_week= DUD_VALUE\n",
    "        self.day_since_epoch= DUD_VALUE\n",
    "        self.day_of_week= ((STARTING_DAY + index - 1) % len(DAYS_OF_WEEK))\n",
    "        \n",
    "        self.daily_epoch_time= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.epoch_time= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.bikes= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.percent_bikes= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.float)\n",
    "\n",
    "    def populate(self, daily_epoch_time, epoch_time, bikes, percent_bikes):\n",
    "        self.daily_epoch_time[daily_epoch_time]= daily_epoch_time\n",
    "        self.epoch_time[daily_epoch_time]= epoch_time\n",
    "        self.bikes[daily_epoch_time]= bikes\n",
    "        self.percent_bikes[daily_epoch_time]= percent_bikes\n",
    "        self.times_populated+= 1\n",
    "\n",
    "class Station:\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.name= DUD_VALUE\n",
    "        self.bike_capacity= DUD_VALUE\n",
    "        self.address= DUD_VALUE\n",
    "        self.latitude= DUD_VALUE\n",
    "        self.longitude= DUD_VALUE\n",
    "        self.data_days= [DataDay(i) for i in range(1, TOTAL_DAYS + 2)] # + 1 because 0 is excluded and + 1 because we want to include the last day, not have it as the rim\n",
    "    \n",
    "    def populate_consts(self, name, bike_capacity, address, latitude, longitude):\n",
    "        self.name= name\n",
    "        self.bike_capacity= bike_capacity\n",
    "        self.address= address\n",
    "        self.latitude= latitude\n",
    "        self.longitude= longitude\n",
    "\n",
    "def get_station_id(name):\n",
    "    try:\n",
    "        index= [x.name for x in stations].index(name)\n",
    "    except ValueError:\n",
    "        index= -1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_capacity= 0 # not in use currently\n",
    "index= []; daily_epoch_time= []; epoch_time= []; percent_bikes= [];\n",
    "stations= [Station(i) for i in range(1, MAX_STATION_ID + 1)] # note: MAX_STATION_ID + 1 is not included in the range\n",
    "indices_to_populate= list(range(1, MAX_STATION_ID + 1))\n",
    "for index in MISSING_STATIONS:\n",
    "    indices_to_populate.remove(index)\n",
    "\n",
    "with open(FILENAME, newline='') as f:\n",
    "    reader = csv.reader(f); next(reader) # skip data header\n",
    "    current_index= 0\n",
    "    try:\n",
    "        while len(indices_to_populate) != 0:\n",
    "            row= next(reader)\n",
    "            if int(row[0]) == current_index: # this 'if' is just for performance\n",
    "                continue\n",
    "            current_index= int(row[0])\n",
    "            if current_index in indices_to_populate:\n",
    "                stations[current_index - 2].populate_consts(row[3], row[4], row[8], row[9], row[10])\n",
    "                indices_to_populate.remove(current_index)\n",
    "                total_capacity+= int(row[4])\n",
    "        \n",
    "        f.seek(0)\n",
    "        reader= csv.reader(f); row= next(reader) # skip data header\n",
    "        for row_i, row in enumerate(reader):\n",
    "            if row_i >= INPUT_ROWS_LIMIT:\n",
    "                break\n",
    "            if int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds()) < 0:\n",
    "                continue\n",
    "            try:\n",
    "                epoch_time= int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "                stations[int(row[0]) - 1].data_days[int(epoch_time / (DATAPOINTS_PER_DAY - 1))].populate( \\\n",
    "                    int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), 0, 0)).total_seconds() / (SECS_IN_5MIN + 1)), \\\n",
    "                    epoch_time, \\\n",
    "                    int(row[6]), \\\n",
    "                    float(\"{:.3f}\".format(float(row[6]) / float(row[4]))))\n",
    "            except IndexError as e:\n",
    "                print(\"\\nTRIED: \", epoch_time, ' / ', DATAPOINTS_PER_DAY, ' = ', int(epoch_time / (DATAPOINTS_PER_DAY - 1)))\n",
    "                print(row[1])\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter= 0\n",
    "# limit= 50\n",
    "# for row_i in range(limit):\n",
    "#     print(\"################# row_i: \",row_i)\n",
    "#     for s_i, station in enumerate(stations):\n",
    "        \n",
    "#         print(stations[s_i].data_days[row_i].day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 01 - Data Prep\n",
    "\n",
    "fullness= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "fullness_in10= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "fullness_in30= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "fullness_in60= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "fullness_percent= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.float)\n",
    "bikes_changes_past5= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "bikes_changes_past15= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "bikes_changes_past45= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), 0, dtype=np.int)\n",
    "day_of_week= np.full((MAX_TIME, len(DAYS_OF_WEEK)), 0, dtype=np.int)\n",
    "hour_of_day= np.full((MAX_TIME, HOURS), 0, dtype=np.float)\n",
    "\n",
    "station_index_decrement= 1 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for epoch_day_i in range(TOTAL_DAYS):\n",
    "    #print(\"########### epoch_day_i: \", epoch_day_i)\n",
    "    x= epoch_day_i * DATAPOINTS_PER_DAY\n",
    "    y= 0\n",
    "    \n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, HOURS), dtype=np.float)\n",
    "    daily_epoch_time= list(range(DATAPOINTS_PER_DAY))\n",
    "    for time_i in daily_epoch_time:\n",
    "        hour= float(\"{:.3f}\".format(time_i / 12))\n",
    "        block[time_i][(int(hour) + 1) % 24]= hour % 1\n",
    "        block[time_i][int(hour)]= 1 - (hour % 1)\n",
    "    hour_of_day[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "    \n",
    "    day= stations[2].data_days[epoch_day_i].day_of_week\n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, len(DAYS_OF_WEEK)), dtype=np.int)\n",
    "    for block_i, sub_arr in enumerate(block):\n",
    "        block[block_i][day]= 1\n",
    "    day_of_week[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "    \n",
    "    for station in stations:\n",
    "        #print(\"###### station.index: \", station.index)\n",
    "        if station.index == 1:\n",
    "            station_index_decrement= 1\n",
    "        if station.index in MISSING_STATIONS:\n",
    "            station_index_decrement+= 1\n",
    "            continue\n",
    "        y= station.index - station_index_decrement\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].percent_bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness_percent[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "        \n",
    "        bikes= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(bikes[2:], (bikes.shape[0] - 2, 1))\n",
    "        fullness_in10[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[6:], (bikes.shape[0] - 6, 1))\n",
    "        fullness_in30[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[12:], (bikes.shape[0] - 12, 1))\n",
    "        fullness_in60[x:x + block.shape[0], y:y + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        block_5minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_15minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_45minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        for block_i in range(len(block)):\n",
    "            five_ago= block[block_i]; fifteen_ago= block[block_i]; fourtyfive_ago= block[block_i];\n",
    "            for decrement in reversed(range(DECREMENTS)): # i.e. [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "                try:\n",
    "                    if block[block_i - min(1, decrement)] == DUD_VALUE or block[block_i - min(3, decrement)] == DUD_VALUE or block[block_i - min(9, decrement)] == DUD_VALUE:\n",
    "                        continue\n",
    "                    fourtyfive_ago= block[block_i - min(9, decrement)]\n",
    "                    fifteen_ago= block[block_i - min(3, decrement)]\n",
    "                    five_ago= block[block_i - min(1, decrement)]\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    print(\"IndexError with \", decrement)\n",
    "                    continue\n",
    "            current= block[block_i]\n",
    "            decrement= 1\n",
    "            while current == DUD_VALUE and decrement < 10:\n",
    "                current= block[block_i - decrement]\n",
    "                decrement+= 1\n",
    "            block_5minchange[block_i]= current - five_ago\n",
    "            block_15minchange[block_i]= current - fifteen_ago\n",
    "            block_45minchange[block_i]= current - fourtyfive_ago\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_5minchange= np.reshape(block_5minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_15minchange= np.reshape(block_15minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_45minchange= np.reshape(block_45minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        bikes_changes_past5[x:x + block.shape[0], y:y + block.shape[1]]= block_5minchange\n",
    "        bikes_changes_past15[x:x + block.shape[0], y:y + block.shape[1]]= block_15minchange\n",
    "        bikes_changes_past45[x:x + block.shape[0], y:y + block.shape[1]]= block_45minchange\n",
    "\n",
    "X= np.full((MAX_TIME, fullness_percent.shape[1] + hour_of_day.shape[1] + day_of_week.shape[1] + bikes_changes_past5.shape[1] * 3), 0, dtype=np.int)\n",
    "#y= np.full((MAX_TIME, ), 0, dtype=np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fullness_percent.shape)\n",
    "print(bikes_changes_past5.shape)\n",
    "print(bikes_changes_past15.shape)\n",
    "print(bikes_changes_past45.shape)\n",
    "print(day_of_week.shape)\n",
    "print(hour_of_day.shape)\n",
    "\n",
    "counter= 0\n",
    "limit= 22051\n",
    "for row_i in range(limit):\n",
    "    print(\"\\n####################################\")\n",
    "#     print(day_of_week[row_i])\n",
    "#     print(hour_of_day[row_i])\n",
    "#     print(fullness_percent[row_i])\n",
    "    print(fullness[row_i])\n",
    "    print(\"---\")\n",
    "    print(fullness_in10[row_i])\n",
    "    print(fullness_in30[row_i])\n",
    "    print(fullness_in60[row_i])\n",
    "#     print(bikes_changes_past5[row_i])\n",
    "#     print(bikes_changes_past15[row_i])\n",
    "#     print(bikes_changes_past45[row_i])\n",
    "    print(\"####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= fullness_percent, hour_of_day, day_of_week, bikes_changes_past5, bikes_changes_past15, bikes_changes_past45\n",
    "#y= fullness in 10 min, 30 min, and 1 hour for 2 stations\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "#regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "#regr.predict(X_test)\n",
    "\n",
    "#print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.array([1, 2, 3, 4, 5])\n",
    "print(y)\n",
    "print(y[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
