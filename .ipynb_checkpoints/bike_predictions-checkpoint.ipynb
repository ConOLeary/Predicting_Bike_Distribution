{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS & DEFINITIONS\n",
    "\n",
    "import csv, sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np; np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "DUD_VALUE= 0 # change from 0 to something like 123 for debugging\n",
    "TOTAL_ROWS= 2228278 # This number is greater than the total amount of rows circa epoch change to 27th, but it still works\n",
    "INPUT_ROWS_LIMIT= TOTAL_ROWS\n",
    "FILENAME= 'dublinbikes_2020_Q1.csv'\n",
    "MAX_STATION_ID= 117\n",
    "SECS_IN_5MIN= 300\n",
    "DATAPOINT_EVERYX_MIN= 5\n",
    "DATAPOINTS_PER_DAY= 288\n",
    "DAYS_OF_WEEK= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] # yes, I consider Monday to be the '0'/start of the week\n",
    "STARTING_DAY= 0 # aka Monday. Because the 27th of Jan 2020 is a Monday\n",
    "MISSING_STATIONS= [117, 116, 70, 60, 46, 35, 20, 14, 1]\n",
    "TOTAL_DAYS= 66 # from 27 / 1 / 2020 to (and including) 1 / 4 / 2020\n",
    "HOURS= 24\n",
    "EPOCH= datetime.datetime(2020, 1, 27, 0, 0)\n",
    "MAX_TIME= int((datetime.datetime(2020,4,2,0,0) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "K= 5\n",
    "STEP_SIZE= 0.02185 # just the magic number that leads to 288 values being generated\n",
    "R= 0.5\n",
    "MAX_HINDSIGHT= 60\n",
    "\n",
    "class DataDay: # ideally this would be nested in the Station class\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.times_populated= 0\n",
    "        self.day_of_week= DUD_VALUE\n",
    "        self.day_since_epoch= DUD_VALUE\n",
    "        self.day_of_week= ((STARTING_DAY + index - 1) % len(DAYS_OF_WEEK))\n",
    "        \n",
    "        self.daily_epoch_time= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.epoch_time= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.bikes= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.int)\n",
    "        self.percent_bikes= np.full(DATAPOINTS_PER_DAY, DUD_VALUE, dtype=np.float)\n",
    "\n",
    "    def populate(self, daily_epoch_time, epoch_time, bikes, percent_bikes):\n",
    "        self.daily_epoch_time[daily_epoch_time]= daily_epoch_time\n",
    "        self.epoch_time[daily_epoch_time]= epoch_time\n",
    "        self.bikes[daily_epoch_time]= bikes\n",
    "        self.percent_bikes[daily_epoch_time]= percent_bikes\n",
    "        self.times_populated+= 1\n",
    "\n",
    "class Station:\n",
    "    def __init__(self, index):\n",
    "        self.index= index\n",
    "        self.name= DUD_VALUE\n",
    "        self.bike_capacity= DUD_VALUE\n",
    "        self.address= DUD_VALUE\n",
    "        self.latitude= DUD_VALUE\n",
    "        self.longitude= DUD_VALUE\n",
    "        self.data_days= [DataDay(i) for i in range(1, TOTAL_DAYS + 2)] # + 1 because 0 is excluded and + 1 because we want to include the last day, not have it as the rim\n",
    "    \n",
    "    def populate_consts(self, name, bike_capacity, address, latitude, longitude):\n",
    "        self.name= name\n",
    "        self.bike_capacity= bike_capacity\n",
    "        self.address= address\n",
    "        self.latitude= latitude\n",
    "        self.longitude= longitude\n",
    "\n",
    "def get_station_id(name):\n",
    "    try:\n",
    "        index= [x.name for x in stations].index(name)\n",
    "    except ValueError:\n",
    "        index= -1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA STRUCTURING\n",
    "\n",
    "total_capacity= 0 # not in use currently\n",
    "index= []; daily_epoch_time= []; epoch_time= []; percent_bikes= [];\n",
    "stations= [Station(i) for i in range(1, MAX_STATION_ID + 1)] # note: MAX_STATION_ID + 1 is not included in the range\n",
    "indices_to_populate= list(range(1, MAX_STATION_ID + 1))\n",
    "for index in MISSING_STATIONS:\n",
    "    indices_to_populate.remove(index)\n",
    "\n",
    "with open(FILENAME, newline='') as f:\n",
    "    reader = csv.reader(f); next(reader) # skip data header\n",
    "    current_index= 0\n",
    "    try:\n",
    "        while len(indices_to_populate) != 0:\n",
    "            row= next(reader)\n",
    "            if int(row[0]) == current_index: # this 'if' is just for performance\n",
    "                continue\n",
    "            current_index= int(row[0])\n",
    "            if current_index in indices_to_populate:\n",
    "                stations[current_index - 2].populate_consts(row[3], row[4], row[8], row[9], row[10])\n",
    "                indices_to_populate.remove(current_index)\n",
    "                total_capacity+= int(row[4])\n",
    "        \n",
    "        f.seek(0)\n",
    "        reader= csv.reader(f); row= next(reader) # skip data header\n",
    "        for row_i, row in enumerate(reader):\n",
    "            if row_i >= INPUT_ROWS_LIMIT:\n",
    "                break\n",
    "            if int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds()) < 0:\n",
    "                continue\n",
    "            try:\n",
    "                epoch_time= int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - EPOCH).total_seconds() / SECS_IN_5MIN)\n",
    "                stations[int(row[0]) - 1].data_days[int(epoch_time / (DATAPOINTS_PER_DAY - 1))].populate( \\\n",
    "                    int((datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), int(row[1][11: 13]), int(row[1][14: 16])) - datetime.datetime(int(row[1][0:4]), int(row[1][5:7]), int(row[1][8:10]), 0, 0)).total_seconds() / (SECS_IN_5MIN + 1)), \\\n",
    "                    epoch_time, \\\n",
    "                    int(row[6]), \\\n",
    "                    float(\"{:.3f}\".format(float(row[6]) / float(row[4]))))\n",
    "            except IndexError as e:\n",
    "                print(\"\\nTRIED: \", epoch_time, ' / ', DATAPOINTS_PER_DAY, ' = ', int(epoch_time / (DATAPOINTS_PER_DAY - 1)))\n",
    "                print(row[1])\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE DATA PREPERATION\n",
    "\n",
    "fullness= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "fullness_in10= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "fullness_in30= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "fullness_in60= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "fullness_percent= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.float)\n",
    "bikes_changes_past5= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "bikes_changes_past15= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "bikes_changes_past45= np.full((MAX_TIME, MAX_STATION_ID - len(MISSING_STATIONS)), DUD_VALUE, dtype=np.int)\n",
    "day_of_week= np.full((MAX_TIME, len(DAYS_OF_WEEK)), DUD_VALUE, dtype=np.int)\n",
    "hour_of_day= np.full((MAX_TIME, HOURS), DUD_VALUE, dtype=np.float)\n",
    "\n",
    "station_index_decrement= 1 # this is a varying offset for the indexing of stations that accounts for missing stations that are being ignored\n",
    "for epoch_day_i in range(TOTAL_DAYS):\n",
    "    #print(\"########### epoch_day_i: \", epoch_day_i)\n",
    "    x_offset= epoch_day_i * DATAPOINTS_PER_DAY\n",
    "    y_offset= 0\n",
    "    \n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, HOURS), dtype=np.float)\n",
    "    daily_epoch_time= list(range(DATAPOINTS_PER_DAY))\n",
    "    for time_i in daily_epoch_time:\n",
    "        hour= float(\"{:.3f}\".format(time_i / 12))\n",
    "        block[time_i][(int(hour) + 1) % 24]= hour % 1\n",
    "        block[time_i][int(hour)]= 1 - (hour % 1)\n",
    "    hour_of_day[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    day= stations[2].data_days[epoch_day_i].day_of_week\n",
    "    block= np.zeros((DATAPOINTS_PER_DAY, len(DAYS_OF_WEEK)), dtype=np.int)\n",
    "    for block_i, sub_arr in enumerate(block):\n",
    "        block[block_i][day]= 1\n",
    "    day_of_week[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "    \n",
    "    for station in stations:\n",
    "        #print(\"###### station.index: \", station.index)\n",
    "        if station.index == 1:\n",
    "            station_index_decrement= 1\n",
    "        if station.index in MISSING_STATIONS:\n",
    "            station_index_decrement+= 1\n",
    "            continue\n",
    "        y_offset= station.index - station_index_decrement\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].percent_bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness_percent[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        fullness[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        bikes= station.data_days[epoch_day_i].bikes\n",
    "        block= np.reshape(bikes[2:], (bikes.shape[0] - 2, 1))\n",
    "        fullness_in10[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[6:], (bikes.shape[0] - 6, 1))\n",
    "        fullness_in30[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        block= np.reshape(bikes[12:], (bikes.shape[0] - 12, 1))\n",
    "        fullness_in60[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block\n",
    "        \n",
    "        block= station.data_days[epoch_day_i].bikes\n",
    "        \n",
    "        block_Xminchange= np.zeros((DATAPOINTS_PER_DAY, ), dtype=np.int)\n",
    "        block_10minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_15minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_30minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_45minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        block_60minchange= np.zeros(DATAPOINTS_PER_DAY, dtype=np.int)\n",
    "        for block_i in range(len(block)):\n",
    "            five_ago= block[block_i]; ten_ago= block[block_i]; fifteen_ago= block[block_i]; thirty_ago= block[block_i]; fourtyfive_ago= block[block_i]; sixty_ago= block[block_i];\n",
    "            for decrement in reversed(range(MAX_HINDSIGHT / DATAPOINT_EVERYX_MIN + 1)): # i.e. [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "                try:\n",
    "                    exit_iteration= False\n",
    "                    for i in range(DECREMENTS)[1:]:\n",
    "                        if block[block_i - min(i, decrement)] == DUD_VALUE:\n",
    "                            exit_iteration= True\n",
    "                    if exit_iteration:\n",
    "                        continue\n",
    "                    fourtyfive_ago= block[block_i - min(9, decrement)]\n",
    "                    fifteen_ago= block[block_i - min(3, decrement)]\n",
    "                    five_ago= block[block_i - min(1, decrement)]\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    print(\"IndexError with \", decrement)\n",
    "                    continue\n",
    "            current= block[block_i]\n",
    "            decrement= 1\n",
    "            while current == DUD_VALUE and decrement < 10:\n",
    "                current= block[block_i - decrement]\n",
    "                decrement+= 1\n",
    "            block_5minchange[block_i]= current - five_ago\n",
    "            block_15minchange[block_i]= current - fifteen_ago\n",
    "            block_45minchange[block_i]= current - fourtyfive_ago\n",
    "        block= np.reshape(block, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_5minchange= np.reshape(block_5minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_15minchange= np.reshape(block_15minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        block_45minchange= np.reshape(block_45minchange, (DATAPOINTS_PER_DAY, 1))\n",
    "        bikes_changes_past5[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block_5minchange\n",
    "        bikes_changes_past15[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block_15minchange\n",
    "        bikes_changes_past45[x_offset:x_offset + block.shape[0], y_offset:y_offset + block.shape[1]]= block_45minchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH DEFINITIONS\n",
    "\n",
    "def run_approach1(station_name):\n",
    "    index= get_station_id(station_name)\n",
    "    \n",
    "    y= np.full((MAX_TIME, 3), 0, dtype=np.int) # change the 3 to a 6 to do both stations at once on the generalised-training form of an approach\n",
    "    y[0:MAX_TIME, 0:1]= np.reshape(fullness_in10[:,index], (MAX_TIME, 1))\n",
    "    y[0:MAX_TIME, 1:2]= np.reshape(fullness_in30[:,index], (MAX_TIME, 1))\n",
    "    y[0:MAX_TIME, 2:3]= np.reshape(fullness_in60[:,index], (MAX_TIME, 1))\n",
    "    #y[0:MAX_TIME, 3:4]= np.reshape(fullness_in10[:,get_station_id(\"CUSTOM HOUSE QUAY\")], (MAX_TIME, 1))\n",
    "    #y[0:MAX_TIME, 4:5]= np.reshape(fullness_in30[:,get_station_id(\"CUSTOM HOUSE QUAY\")], (MAX_TIME, 1))\n",
    "    #y[0:MAX_TIME, 5:6]= np.reshape(fullness_in60[:,get_station_id(\"CUSTOM HOUSE QUAY\")], (MAX_TIME, 1))\n",
    "\n",
    "    X= np.full((MAX_TIME, hour_of_day.shape[1] + day_of_week.shape[1] + 4 \\\n",
    "                #* bikes_changes_past5.shape[1] \\\n",
    "               ), 0, dtype=np.float)\n",
    "    X[0:MAX_TIME, 0:7]= day_of_week\n",
    "    X[0:MAX_TIME, 7:31]= hour_of_day\n",
    "    X[0:MAX_TIME, 31:32]= fullness_percent[0:MAX_TIME, index:index+1]\n",
    "    X[0:MAX_TIME, 32:33]= bikes_changes_past5[0:MAX_TIME, index:index+1]\n",
    "    X[0:MAX_TIME, 33:34]= bikes_changes_past15[0:MAX_TIME, index:index+1]\n",
    "    X[0:MAX_TIME, 34:35]= bikes_changes_past45[0:MAX_TIME, index:index+1]\n",
    "    # X[0:MAX_TIME, 31:139]= fullness_percent\n",
    "    # X[0:MAX_TIME, 139:247]= bikes_changes_past5\n",
    "    # X[0:MAX_TIME, 247:355]= bikes_changes_past15\n",
    "    # X[0:MAX_TIME, 355:463]= bikes_changes_past45\n",
    "\n",
    "\n",
    "    kf= KFold(n_splits= K)\n",
    "    kf.get_n_splits(X)\n",
    "    score_sum= 0.0\n",
    "    i= 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test= X[train_index], X[test_index]\n",
    "        y_train, y_test= y[train_index], y[test_index]\n",
    "        regr= MLPRegressor(random_state= 1, max_iter= 1000).fit(X_train, y_train)\n",
    "        y_pred= regr.predict(X_test)\n",
    "        score_sum+= regr.score(X_test, y_test)\n",
    "        print(\"Data split \", i, \" accuracy: \", regr.score(X_test, y_test) * 100, \" %\")\n",
    "        i+= 1\n",
    "    print(\"\\nAverage accuracy of model: \", (score_sum / K) * 100, \" %\")\n",
    "\n",
    "    # Below is alternative evaluation code\n",
    "\n",
    "    # regr= MLPRegressor(random_state= 1, max_iter= 500).fit(X_train, y_train)\n",
    "    # scores= cross_val_score(regr, X, y, cv=5)\n",
    "    # print(scores)\n",
    "    \n",
    "def run_approach2(station_name):\n",
    "    X= np.full((MAX_TIME, 2 + 3 \\\n",
    "            #* bikes_changes_past5.shape[1] \\\n",
    "           ), -1, dtype=np.float)\n",
    "    \n",
    "    positions= []; t= 0\n",
    "    while t < 2 * math.pi:\n",
    "        positions.append((1 - (R * math.cos(t) + R), R * math.sin(t) + R))\n",
    "        t+= STEP_SIZE\n",
    "    pos_i= 0\n",
    "    for time_i in range(MAX_TIME):\n",
    "        X[time_i, 0]= positions[pos_i][0]\n",
    "        X[time_i, 1]= positions[pos_i][1]\n",
    "        pos_i= (pos_i + 1) % len(positions)\n",
    "    \n",
    "    index= get_station_id(station_name)\n",
    "    X[0:MAX_TIME, 2:3]= bikes_changes_past5[0:MAX_TIME, index:index+1] \n",
    "    X[0:MAX_TIME, 3:4]= bikes_changes_past15[0:MAX_TIME, index:index+1] \n",
    "    X[0:MAX_TIME, 4:5]= fullness_percent[0:MAX_TIME, index:index+1] \n",
    "    # X[0:MAX_TIME, 2:110]= bikes_changes_past5\n",
    "    # X[0:MAX_TIME, 110:218]= bikes_changes_past15\n",
    "    # X[0:MAX_TIME, 218:326]= fullness_percent\n",
    "    \n",
    "    y= np.full((MAX_TIME, 3), 0, dtype=np.int)\n",
    "    y[0:MAX_TIME, 0:1]= np.reshape(fullness_in10[:,index], (MAX_TIME, 1))\n",
    "    y[0:MAX_TIME, 1:2]= np.reshape(fullness_in30[:,index], (MAX_TIME, 1))\n",
    "    y[0:MAX_TIME, 2:3]= np.reshape(fullness_in60[:,index], (MAX_TIME, 1))\n",
    "    \n",
    "    neigh= KNeighborsRegressor(n_neighbors= 30, weights='distance')\n",
    "    cv_scores= cross_val_score(neigh, X, y, cv=5)\n",
    "    print(cv_scores) # print each cv score (accuracy) and average them\n",
    "    print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94008073 0.9340632  0.95706052 0.94543584 0.35396178]\n",
      "cv_scores mean:0.8261204137171468\n",
      "[0.7654187  0.80113349 0.79444586 0.7738909  0.63637251]\n",
      "cv_scores mean:0.754252291975149\n"
     ]
    }
   ],
   "source": [
    "# DRIVER\n",
    "\n",
    "run_approach2(\"PORTOBELLO ROAD\")\n",
    "run_approach2(\"CUSTOM HOUSE QUAY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
